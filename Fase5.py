"""
# Tech Challenge Fase 5
# Data Analytics FIAP - 05/2025
# Alison S√©rgio de Amarins Germano - RM 357521

*Ambiente de desenvolvimento utilizado foi o Colab e VS CODE

**1. Empresa enfrenta dificuldades para identificar os melhores candidatos para cada vaga e, 
inversamente, oferecer as melhores vagas aos profissionais cadastrados.

"""
# Importando e Aplicando o √°lias a cada biblioteca
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
import io
from PIL import Image
from gtts import gTTS
# Importa√ß√£o da fun√ß√£o que carrega o zip
from ler_dados_applicants_zip import carregar_csv_de_zip
# Texto que ser√° narrado
texto_narracao = """
Bem-vindo ao sistema de recomenda√ß√£o de vagas. Esta solu√ß√£o ajuda empresas a encontrar os candidatos ideais 
analisando perfis, palavras-chave e hist√≥ricos de aceites. 
Os dados foram preparados no Colab e a experi√™ncia criada com Streamlit."""
# Cabe√ßalho
st.write("# Tech Challenge Fase 5")
st.markdown("**Alison S√©rgio de Amarins Germano - RM 357521**") 
st.markdown("**Data Analytics FIAP - 05/2025 - 6DTAT**") 
st.write("## Sistema de Recomenda√ß√£o de Vagas e Candidatos")
st.image("job_match_humanizado.png", caption='"O prazer no trabalho aperfei√ßoa a obra." - Arist√≥teles')
st.markdown("**Problema:**")
st.markdown("""
Empresa enfrenta dificuldades para identificar os melhores candidatos para cada vaga e, 
inversamente, oferecer as melhores vagas aos profissionais cadastrados.
""")

# Gerar e salvar √°udio MP3
audio_file = "narracao_apresentacao.mp3"
if os.path.exists(audio_file):
    os.remove(audio_file)

tts = gTTS(text=texto_narracao, lang='pt')
tts.save(audio_file)

# Painel de Introdu√ß√£o Interativo
with st.expander("‚ÑπÔ∏è Sobre este sistema de recomenda√ß√£o", expanded=True):
    # Tocar o √°udio com um player
    st.audio(audio_file, format="audio/mp3")

    st.markdown("""
    Este sistema tem como objetivo **recomendar automaticamente os melhores pares entre vagas e candidatos**.

    üîç **Como funciona:**
    - Utiliza t√©cnicas de **Processamento de Linguagem Natural (NLP)** para extrair palavras-chave de curr√≠culos e vagas.
    - Calcula a similaridade entre candidatos e vagas usando **TF-IDF + Cosine Similarity**.
    - Usa a coluna `data_aceite` como indica√ß√£o real de que houve **match verdadeiro**, permitindo an√°lises supervisionadas.

    üìä **Gr√°ficos dispon√≠veis:**
    - **Distribui√ß√£o de Aceites:** mostra quantos candidatos aceitaram as vagas.
    - **Top 5 Clientes e Candidatos:** an√°lise dos melhores com base na m√©dia dos scores.
    - **Heatmap:** compara√ß√£o entre origens dos rankings e clientes.
    - **Matches Reais com Alto Score:** candidatos aceitos com alta compatibilidade.

    üîß **Filtros dispon√≠veis:** selecione origem do ranking ou t√≠tulo da vaga.

    ---
    ‚öôÔ∏è Projeto constru√≠do em duas etapas:
    - Pr√©-processamento e Machine Learning via **Google Colab**.
    - Visualiza√ß√£o e Storytelling com **Streamlit no VS Code**.

    """)
# Carregar os dados
assert os.path.exists("base_final_ml_com_nome_cliente.zip"), "Arquivo base_final_ml_com_nome_cliente.zip n√£o encontrado"
#df = pd.read_csv("base_final_ml_com_nome_cliente.csv")
df = carregar_csv_de_zip("base_final_ml_com_nome_cliente.zip", "base_final_ml_com_nome_cliente.csv", ",")
# Verifica√ß√µes e carregamento
assert os.path.exists("dados_applicants_limpo.zip"), "Arquivo dados_applicants_limpo.zip n√£o encontrado"
df_applicants = carregar_csv_de_zip("dados_applicants_limpo.zip", "dados_applicants_limpo.csv",";")
#
assert os.path.exists("df_base.zip"), "Arquivo df_base.zip n√£o encontrado"
df_base = carregar_csv_de_zip("df_base.zip", "df_base.csv",";")
#
df_vagas = carregar_csv_de_zip("df_vagas_limpo.zip", "df_vagas_limpo.csv",";")
# Criar coluna bin√°ria para match real
df_applicants['match_real'] = df_applicants['data_aceite'].notnull().astype(int)
df = df.merge(df_applicants[['codigo_profissional', 'match_real']], on='codigo_profissional', how='left')

df['match_real'] = df['match_real'].fillna(0).astype(int)
df = df.drop_duplicates(subset='codigo_profissional')

# Filtros
# Calcular top 5 clientes por score m√©dio
top5_clientes = (
    df.groupby('cliente')['score']
    .mean()
    .sort_values(ascending=False)
    .head(5)
    .index
    .tolist()
)
# Filtro por origem do ranking
origens = df['ranking_origem'].dropna().unique().tolist()
origens_selecionadas = st.sidebar.multiselect("Filtrar por Origem do Ranking", options=origens, default=origens)
df_filtrado = df[df['ranking_origem'].isin(origens_selecionadas)]
#-------------------------------------------------------------------------
# Gr√°fico 1 ‚Äì Filtrado por Origem do Ranking
st.subheader("Distribui√ß√£o de Aceites Reais por Origem")
st.caption("Este gr√°fico mostra a quantidade de candidatos que aceitaram ou n√£o as vagas recomendadas.")
fig1, ax1 = plt.subplots()
sns.countplot(data=df_filtrado, x='match_real', palette='Set2', ax=ax1)
ax1.set_title("Distribui√ß√£o de Aceites Reais")
ax1.set_xlabel("Match Real (0 = N√£o Aceitou, 1 = Aceitou)")
ax1.set_ylabel("Quantidade")
st.pyplot(fig1)
#-------------------------------------------------------------------------
# Gr√°fico 2 ‚Äì Top 5 Score M√©dio por Cliente
st.subheader("Top 5 Clientes com Maior Score M√©dio")
st.caption("Clientes que receberam candidatos com maior compatibilidade m√©dia de perfil.")
fig2, ax2 = plt.subplots(figsize=(10, 5))
top5_clientes = (
    df_filtrado.groupby('cliente')['score']
    .mean()
    .sort_values(ascending=True)
)
# Verificar se h√° dados antes de plotar
if not top5_clientes.empty:
    top5_clientes.tail(5).plot(kind='barh', ax=ax2, color='skyblue')
    ax2.set_title("Top 5 Score M√©dio por Cliente")
    ax2.set_xlabel("Score M√©dio")
    ax2.set_ylabel("Cliente")
    st.pyplot(fig2)
else:
    #st.warning("‚ö†Ô∏è Nenhum dado dispon√≠vel para o gr√°fico de Score M√©dio por Cliente com os filtros aplicados.")
    st.warning(f"‚ö†Ô∏è Nenhum dado dispon√≠vel para os clientes selecionados ({', '.join(clientes)}).")
#-------------------------------------------------------------------------
# Gr√°fico 3 - Score M√©dio por Cliente e Origem do Ranking (Top 10 Clientes)
st.title("üî• Score M√©dio por Cliente e Origem do Ranking (Top 10 Clientes)")
st.caption("Mostra como a qualidade (score) das recomenda√ß√µes varia entre os clientes e a origem do ranking (vaga/candidato).")
# Preencher valores nulos
df['cliente'] = df['cliente'].fillna("desconhecido")
df['ranking_origem'] = df['ranking_origem'].fillna("indefinido")
# Filtrar Top 10 clientes
top_clientes = df['cliente'].value_counts().head(10).index
df_top = df[df['cliente'].isin(top_clientes)]
# Criar a tabela din√¢mica (pivot)
pivot_simplificado = df_top.pivot_table(
    index='cliente',
    columns='ranking_origem',
    values='score',
    aggfunc='mean'
)
# Plotar o heatmap
fig, ax = plt.subplots(figsize=(12, 6))
sns.heatmap(
    pivot_simplificado,
    cmap='YlGnBu',
    annot=True,
    fmt=".2f",
    linewidths=0.5,
    cbar_kws={'label': 'Score M√©dio'},
    ax=ax
)
ax.set_title("üî• Score M√©dio por Cliente e Origem do Ranking (Top 10 Clientes)")
ax.set_xlabel("Origem do Ranking")
ax.set_ylabel("Cliente")
plt.tight_layout()
# Exibir no Streamlit
st.pyplot(fig)
#-------------------------------------------------------------------------
# Gr√°fico 4 - Exemplo Real de Recomenda√ß√£o
st.title("üßæ Exemplo Real de Recomenda√ß√£o")
st.caption("Visualiza√ß√£o da performance m√©dia das recomenda√ß√µes por cliente e origem do ranking.")
# Agrupar por vaga e contar apenas candidatos com score
vagas_com_score = df[df['score'].notnull()].groupby('titulo_vaga').size()
# Selecionar apenas vagas com pelo menos 1 candidato com score
vagas_validas = vagas_com_score[vagas_com_score > 0].index.tolist()
# Filtrar dropdown para exibir s√≥ essas vagas
vaga_selecionada = st.selectbox("Selecione uma vaga", sorted(vagas_validas))
# Filtrar os candidatos da vaga selecionada
df_vaga_ex = df[df['titulo_vaga'] == vaga_selecionada]
top5 = df_vaga_ex.sort_values(by='score', ascending=False).head(5)
#
if top5.empty:
    st.warning("‚ö†Ô∏è Nenhum candidato encontrado para essa vaga.")
else:
    st.subheader("Candidatos :")
    st.write(top5[['nome', 'cliente', 'score']].reset_index(drop=True))
#-------------------------------------------------------------------------
# Gr√°fico 5 - Exibir Matches Reais (Aceitos) com Alto Score 
st.title("üì§ Exibir Matches Reais (Aceitos) com Alto Score")
st.caption("Exibe combina√ß√µes bem-sucedidas (match_real = 1) com alta similaridade (score ‚â• 0.8).")
# --- Multiselect de ranking_origem ---
ranking_opcoes = df['ranking_origem'].dropna().unique().tolist()
ranking_selecionados = st.multiselect(
    "Filtrar por Origem do Ranking",
    options=ranking_opcoes,
    default=ranking_opcoes,
    key="ranking_origem_filter"  # üîë ID √∫nico para evitar conflito
)
# --- Filtrar por matches reais, score alto e origens selecionadas ---
df_export = df[
    (df['match_real'] == 1) &
    (df['score'] >= 0.8) &
    (df['ranking_origem'].isin(ranking_selecionados))
]

# --- Remover duplicatas por nome + vaga + cliente ---
df_export = df_export.drop_duplicates(subset=['nome', 'titulo_vaga', 'cliente'])
# --- Selecionar colunas para exibi√ß√£o e ordena√ß√£o ---
df_resultado = df_export[['nome', 'titulo_vaga', 'cliente', 'score']].sort_values(by='score', ascending=False)
# --- Exibir resultado ---
st.write(df_resultado.reset_index(drop=True))
# --- Gerar CSV e bot√£o de download ---
csv = df_resultado.to_csv(index=False).encode('utf-8')
st.download_button(
    label="üì• Baixar CSV com Matches Reais",
    data=csv,
    file_name='melhores_matches_reais.csv',
    mime='text/csv'
)
#-------------------------------------------------------------------------
st.title("Conclus√£o")
with st.expander("üìò Ver Conclus√£o do Projeto"):
    st.markdown("### üßæ Conclus√£o do Projeto")
    st.markdown("""
    O projeto Fase 5 (Datathon) teve como principal objetivo desenvolver um sistema de recomenda√ß√£o inteligente que conectasse candidatos e vagas com base em crit√©rios t√©cnicos, lingu√≠sticos e hist√≥ricos de aceita√ß√£o real. Para atingir esse objetivo, foi utilizada uma abordagem estruturada, dividindo o projeto em duas frentes principais:
    """)

    st.markdown("#### 1Ô∏è‚É£ Google Colab ‚Äì Processamento e Modelagem de Dados")
    st.markdown("""
    Nesta etapa, foi realizada toda a **An√°lise Explorat√≥ria de Dados (EDA)**, **limpeza e tratamento de inconsist√™ncias**, normaliza√ß√£o de estruturas complexas (como listas em colunas), al√©m da aplica√ß√£o de **t√©cnicas de NLP (Processamento de Linguagem Natural)** para extra√ß√£o de palavras-chave tanto dos curr√≠culos quanto das descri√ß√µes das vagas.  
    A partir dessas informa√ß√µes, foram constru√≠das bases estruturadas para **c√°lculo de similaridade textual com TF-IDF**, gerando scores de match entre candidatos e vagas. Tamb√©m foi feita a engenharia de vari√°veis e a identifica√ß√£o de casos reais de aceite por meio da vari√°vel `data_aceite`, permitindo criar uma **vari√°vel alvo (match_real)** para an√°lises supervisionadas futuras.
    """)

    st.markdown("#### 2Ô∏è‚É£ Streamlit ‚Äì Interface Interativa e Storytelling")
    st.markdown("""
    Com as bases prontas, foi migrada para o ambiente **Streamlit** para construir uma interface de **an√°lise visual e tomada de decis√£o**.  
    Nesta fase, o foco foi na cria√ß√£o de gr√°ficos interativos, filtros din√¢micos e consultas espec√≠ficas, como o *Top 5 candidatos por vaga* ou *Top 5 vagas por candidato*.  
    Foram inclu√≠dos ainda filtros por origem do ranking, permitindo aos usu√°rios explorarem os dados de forma intuitiva e direcionada.  

    Um painel anal√≠tico e humanizado com storytelling orienta a interpreta√ß√£o dos resultados, oferecendo n√£o apenas uma visualiza√ß√£o, mas tamb√©m **insights de valor para recrutamento inteligente**.
    """)

    st.markdown("### üîç Conclus√£o T√©cnica do Sistema")
    st.markdown("""
    Este modelo h√≠brido entre **Colab (processamento e modelagem)** e **Streamlit (visualiza√ß√£o e entrega)** se mostrou eficiente e robusto para o objetivo proposto, permitindo separar claramente o esfor√ßo computacional da experi√™ncia final de uso.  

    üí° **Observa√ß√£o:** Por se tratar de um **prot√≥tipo funcional**, foi utilizada uma **base de dados reduzida**, com o objetivo de otimizar desempenho e facilitar testes durante o desenvolvimento iterativo.  

    ‚öôÔ∏è Entretanto, como toda solu√ß√£o baseada em dados, o modelo ainda **demanda valida√ß√µes adicionais** e **ciclos cont√≠nuos de aprimoramento**, especialmente para:  
    - Aumentar a **assertividade nas recomenda√ß√µes**  
    - Proporcionar uma **experi√™ncia mais fluida e estrat√©gica** ao processo de recrutamento.
    """)


